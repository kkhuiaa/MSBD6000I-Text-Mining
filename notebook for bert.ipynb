{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert reference link\n",
    "# https://medium.com/@aieeshashafique/feature-extraction-from-bert-25887ed2152a\n",
    "# https://github.com/AyeshaShafique/bert-feature-extraction-tf-2.0/blob/master/bert_embeddings_with_tensorflow_2_0.ipynb\n",
    "# https://colab.research.google.com/drive/1hMLd5-r82FrnFnBub-B-fVW78Px4KPX1#scrollTo=Ik3xqHqXM_lN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow==2.0\n",
    "#!pip install tensorflow_hub #0.8.0\n",
    "#!pip install bert-for-tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model \n",
    "import bert\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version:  2.0.0\n",
      "Hub version:  0.8.0\n"
     ]
    }
   ],
   "source": [
    "print(\"TF version: \", tf.__version__)\n",
    "print(\"Hub version: \", hub.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 256\n",
    "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
    " name=\"input_word_ids\")\n",
    "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
    " name=\"input_mask\")\n",
    "segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
    " name=\"segment_ids\")\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
    " trainable=False)\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=[pooled_output, sequence_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See BERT paper: https://arxiv.org/pdf/1810.04805.pdf\n",
    "# And BERT implementation convert_single_example() at https://github.com/google-research/bert/blob/master/run_classifier.py\n",
    "\n",
    "def get_masks(tokens, max_seq_length):\n",
    "    \"\"\"Mask for padding\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "\n",
    "def get_segments(tokens, max_seq_length):\n",
    "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    segments = []\n",
    "    current_segment_id = 0\n",
    "    for token in tokens:\n",
    "        segments.append(current_segment_id)\n",
    "        if token == \"[SEP]\":\n",
    "            current_segment_id = 1\n",
    "    return segments + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "\n",
    "def get_ids(tokens, tokenizer, max_seq_length):\n",
    "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FullTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "#https://github.com/google-research/bert/blob/master/tokenization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = FullTokenizer(vocab_file, do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source file\n",
    "data_string = '20171001-20200430'\n",
    "path_news = './data/news_{}.gzip'.format(data_string)\n",
    "path_price = './data/price_{}.gzip'.format(data_string)\n",
    "df_news = pd.read_csv(path_news,compression='gzip',index_col = 0)\n",
    "df_price = pd.read_csv(path_price,compression='gzip',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234\n"
     ]
    }
   ],
   "source": [
    "# check the max len of the whole thing\n",
    "checklen = []\n",
    "for i in np.arange(df_news.shape[0]):\n",
    "\n",
    "    s1 = df_news.loc[i,'title']\n",
    "    s2 = df_news.loc[i,'description']\n",
    "    if type(s1)!= str: \n",
    "        s1=\"\"\n",
    "    if type(s2)!= str: \n",
    "        s2=\"\"\n",
    "            \n",
    "    \n",
    "    stokens1 = tokenizer.tokenize(s1)\n",
    "    stokens2 = tokenizer.tokenize(s2)\n",
    "    stokens = [\"[CLS]\"] + stokens1 + [\"[SEP]\"]+ stokens2 + [\"[SEP]\"]\n",
    "    checklen.append(len(stokens))\n",
    "    \n",
    "print(np.max(checklen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert_output = pd.DataFrame(columns = ['title']+['output_'+str(i) for i in np.arange(768)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5347 out of 5348"
     ]
    }
   ],
   "source": [
    "#s = \"Hi we are using BERT\"\n",
    "#s = \"I'm testing the model with adfadfasdfafd wrong words\"\n",
    "\n",
    "for i in np.arange(df_news.shape[0]):\n",
    "\n",
    "    print('\\r {} out of {}'.format(i,df_news.shape[0]),end='')\n",
    "    s1 = df_news.loc[i,'title']\n",
    "    s2 = df_news.loc[i,'description']\n",
    "    \n",
    "    if type(s1)!= str: \n",
    "        s1=\"\"\n",
    "    if type(s2)!= str: \n",
    "        s2=\"\"\n",
    "    \n",
    "    s1_1 = s1.replace('tencent','company').replace('Tencent','company')\n",
    "    s2_1 = s2.replace('tencent','company').replace('Tencent','company')\n",
    "    \n",
    "    stokens1 = tokenizer.tokenize(s1_1)\n",
    "    stokens2 = tokenizer.tokenize(s2_1)\n",
    "    stokens = [\"[CLS]\"] + stokens1 + [\"[SEP]\"]+ stokens2 + [\"[SEP]\"]\n",
    "    \n",
    "    input_ids = get_ids(stokens, tokenizer, max_seq_length)\n",
    "    input_masks = get_masks(stokens, max_seq_length)\n",
    "    input_segments = get_segments(stokens, max_seq_length)\n",
    "    pool_embs, all_embs = model.predict([[input_ids],[input_masks],[input_segments]])\n",
    "    df_bert_output.loc[i,'title'] = s1 \n",
    "    df_bert_output.loc[i, 1:] = pool_embs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert_output.to_csv('bert_output{}_v1.gzip'.format(data_string),index=False,compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert_output.to_csv('bert_output{}.csv'.format(data_string),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5347 out of 5348"
     ]
    }
   ],
   "source": [
    "#s = \"Hi we are using BERT\"\n",
    "#s = \"I'm testing the model with adfadfasdfafd wrong words\"\n",
    "\n",
    "for i in np.arange(df_news.shape[0]):\n",
    "    print(\"\\r {} out of {}\".format(i,len(df_news)),end=\"\")\n",
    "    s1 = df_news.loc[i,'title']\n",
    "    s2 = df_news.loc[i,'description']\n",
    "    if type(s1)!= str: \n",
    "        s1=\"\"\n",
    "    if type(s2)!= str: \n",
    "        s2=\"\"\n",
    "            \n",
    "    if ((df_pastnews['title']==s1).any()==True) and s1!= \"\":\n",
    "        df_bert_output.loc[i,'title'] = s1 \n",
    "        df_bert_output.loc[i, 1:] = df_pastnews[df_pastnews['title']==s1].values[0][1:]\n",
    "    else:\n",
    "        stokens1 = tokenizer.tokenize(s1)\n",
    "        stokens2 = tokenizer.tokenize(s2)\n",
    "        stokens = [\"[CLS]\"] + stokens1 + [\"[SEP]\"]+ stokens2 + [\"[SEP]\"]\n",
    "\n",
    "        input_ids = get_ids(stokens, tokenizer, max_seq_length)\n",
    "        input_masks = get_masks(stokens, max_seq_length)\n",
    "        input_segments = get_segments(stokens, max_seq_length)\n",
    "        pool_embs, all_embs = model.predict([[input_ids],[input_masks],[input_segments]])\n",
    "        df_bert_output.loc[i,'title'] = s1 \n",
    "        df_bert_output.loc[i, 1:] = pool_embs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for inspecting individual record -- testing\n",
    "_rows = 1432\n",
    "s1 = df_news.loc[_rows,'title']\n",
    "s2 = df_news.loc[_rows,'description']\n",
    "stokens1 = tokenizer.tokenize(s1)\n",
    "stokens2 = tokenizer.tokenize(s2)\n",
    "stokens = [\"[CLS]\"] + stokens1 + [\"[SEP]\"]+ stokens2 + [\"[SEP]\"]\n",
    "input_ids = get_ids(stokens, tokenizer, max_seq_length)\n",
    "input_masks = get_masks(stokens, max_seq_length)\n",
    "input_segments = get_segments(stokens, max_seq_length)\n",
    "pool_embs, all_embs = model.predict([[input_ids],[input_masks],[input_segments]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(df_bert_output).any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'ten', '##cent', 'music', 'explores', 'anticipated', 'huge', 'ip', '##o', 'for', 'its', 'streaming', 'music', 'service', '[SEP]', 'china', '’', 's', 'largest', 'music', 'streaming', 'company', ',', 'ten', '##cent', 'music', 'entertainment', 'group', ',', 'is', 'poised', 'to', 'create', 'an', 'initial', 'public', 'offering', '(', 'ip', '##o', ')', 'and', 'is', 'negotiating', 'with', 'several', 'banks', 'for', 'under', '##writing', '.', 'the', 'wall', 'street', 'journal', 'reported', 'that', 'the', 'successful', 'debut', 'of', 'spot', '##ify', 't', '…', '[SEP]']\n",
      "[101, 2702, 13013, 2189, 15102, 11436, 4121, 12997, 2080, 2005, 2049, 11058, 2189, 2326, 102, 2859, 1521, 1055, 2922, 2189, 11058, 2194, 1010, 2702, 13013, 2189, 4024, 2177, 1010, 2003, 22303, 2000, 3443, 2019, 3988, 2270, 5378, 1006, 12997, 2080, 1007, 1998, 2003, 18875, 2007, 2195, 5085, 2005, 2104, 18560, 1012, 1996, 2813, 2395, 3485, 2988, 2008, 1996, 3144, 2834, 1997, 3962, 8757, 1056, 1529, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(stokens)\n",
    "print(input_ids)\n",
    "print(input_masks)\n",
    "print(input_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'company is company bad'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Tencent is tencent bad'.replace('tencent','company').replace('Tencent','company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>content</th>\n",
       "      <th>from</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Samuel Wade</td>\n",
       "      <td>Katy Perry, Publishers, and Self-censorship in...</td>\n",
       "      <td>On Monday, CDT Chinese reposted a letter circu...</td>\n",
       "      <td>https://chinadigitaltimes.net/2017/11/katy-per...</td>\n",
       "      <td>2017-11-08T02:59:56Z</td>\n",
       "      <td>On Monday, CDT Chinese reposted a letter circu...</td>\n",
       "      <td>Chinadigitaltimes.net</td>\n",
       "      <td>2017-11-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jesse Hamilton</td>\n",
       "      <td>Bank of Amazon? Regulator Floats Idea of Mergi...</td>\n",
       "      <td>Bloomberg Bank of Amazon? Regulator Floats Ide...</td>\n",
       "      <td>https://www.bloomberg.com/news/articles/2017-1...</td>\n",
       "      <td>2017-11-08T15:07:48Z</td>\n",
       "      <td>Bank of Amazon. Facebook Financial. Wal-Bank. ...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>2017-11-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Video games could be next for Snapchat, China'...</td>\n",
       "      <td>Chinese gaming and social media company Tencen...</td>\n",
       "      <td>https://japantoday.com/category/tech/update-2-...</td>\n",
       "      <td>2017-11-09T22:24:06Z</td>\n",
       "      <td>Chinese gaming and social media company Tencen...</td>\n",
       "      <td>Japantoday.com</td>\n",
       "      <td>2017-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tim Dixon</td>\n",
       "      <td>DiDi’s Huge Role In The Quickly Developing Chi...</td>\n",
       "      <td>Didi Chuxing (China's Uber-like ride-hailing s...</td>\n",
       "      <td>https://cleantechnica.com/2017/11/09/didis-hug...</td>\n",
       "      <td>2017-11-09T23:50:30Z</td>\n",
       "      <td>Cars Published on November 9th, 2017 | by Tim ...</td>\n",
       "      <td>Cleantechnica.com</td>\n",
       "      <td>2017-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Why You Should Buy JD.Com Inc(ADR) Stock Immed...</td>\n",
       "      <td>Shares of JD.com Inc(ADR) (NASDAQ:JD) have set...</td>\n",
       "      <td>https://finance.yahoo.com/news/why-buy-jd-com-...</td>\n",
       "      <td>2017-11-09T17:05:21Z</td>\n",
       "      <td>Shares of JD.com Inc(ADR) (NASDAQ: JD ) have s...</td>\n",
       "      <td>Yahoo.com</td>\n",
       "      <td>2017-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5343</th>\n",
       "      <td>Li, R., Pei, S., Chen, B., Song, Y., Zhang, T....</td>\n",
       "      <td>Substantial undocumented infection facilitates...</td>\n",
       "      <td>The virus causing coronavirus disease 2019 (CO...</td>\n",
       "      <td>https://science.sciencemag.org/content/368/649...</td>\n",
       "      <td>2020-04-30T17:38:23Z</td>\n",
       "      <td>Abstract\\r\\nEstimation of the prevalence and c...</td>\n",
       "      <td>Sciencemag.org</td>\n",
       "      <td>2020-04-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5344</th>\n",
       "      <td>Cointelegraph By Marie Huillet</td>\n",
       "      <td>Chinese Internet Giant Tencent Launches Blockc...</td>\n",
       "      <td>Tencent, the operator of major Chinese social ...</td>\n",
       "      <td>https://cointelegraph.com/news/chinese-interne...</td>\n",
       "      <td>2020-04-30T10:55:00Z</td>\n",
       "      <td>Tencent, the operator of Chinese social media ...</td>\n",
       "      <td>Cointelegraph.com</td>\n",
       "      <td>2020-04-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5345</th>\n",
       "      <td>Chris Eggertsen</td>\n",
       "      <td>The Deals: HyperX Teams With Hit Command for L...</td>\n",
       "      <td>A roundup of notable music industry deals from...</td>\n",
       "      <td>https://www.billboard.com/articles/business/93...</td>\n",
       "      <td>2020-04-30T13:00:22Z</td>\n",
       "      <td>Gaming and esports brand HyperX will collabora...</td>\n",
       "      <td>Billboard.com</td>\n",
       "      <td>2020-04-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5346</th>\n",
       "      <td>rawmeatcowboy</td>\n",
       "      <td>Tencent looking to release numerous amiibo in ...</td>\n",
       "      <td>Looks like Tencent has plans to release some a...</td>\n",
       "      <td>https://gonintendo.com/stories/360246-tencent-...</td>\n",
       "      <td>2020-04-30T13:30:00Z</td>\n",
       "      <td>Looks like Tencent has plans to release some a...</td>\n",
       "      <td>Gonintendo.com</td>\n",
       "      <td>2020-04-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5347</th>\n",
       "      <td>Adelaide Changole</td>\n",
       "      <td>South Africa Stocks Are on Track for a Record ...</td>\n",
       "      <td>(Bloomberg) -- Unprecedented demand for online...</td>\n",
       "      <td>https://finance.yahoo.com/news/south-africa-st...</td>\n",
       "      <td>2020-04-30T06:50:05Z</td>\n",
       "      <td>(Bloomberg) --\\r\\nUnprecedented demand for onl...</td>\n",
       "      <td>Yahoo.com</td>\n",
       "      <td>2020-04-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5348 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 author  \\\n",
       "0                                           Samuel Wade   \n",
       "1                                        Jesse Hamilton   \n",
       "2                                                   NaN   \n",
       "3                                             Tim Dixon   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "5343  Li, R., Pei, S., Chen, B., Song, Y., Zhang, T....   \n",
       "5344                     Cointelegraph By Marie Huillet   \n",
       "5345                                    Chris Eggertsen   \n",
       "5346                                      rawmeatcowboy   \n",
       "5347                                  Adelaide Changole   \n",
       "\n",
       "                                                  title  \\\n",
       "0     Katy Perry, Publishers, and Self-censorship in...   \n",
       "1     Bank of Amazon? Regulator Floats Idea of Mergi...   \n",
       "2     Video games could be next for Snapchat, China'...   \n",
       "3     DiDi’s Huge Role In The Quickly Developing Chi...   \n",
       "4     Why You Should Buy JD.Com Inc(ADR) Stock Immed...   \n",
       "...                                                 ...   \n",
       "5343  Substantial undocumented infection facilitates...   \n",
       "5344  Chinese Internet Giant Tencent Launches Blockc...   \n",
       "5345  The Deals: HyperX Teams With Hit Command for L...   \n",
       "5346  Tencent looking to release numerous amiibo in ...   \n",
       "5347  South Africa Stocks Are on Track for a Record ...   \n",
       "\n",
       "                                            description  \\\n",
       "0     On Monday, CDT Chinese reposted a letter circu...   \n",
       "1     Bloomberg Bank of Amazon? Regulator Floats Ide...   \n",
       "2     Chinese gaming and social media company Tencen...   \n",
       "3     Didi Chuxing (China's Uber-like ride-hailing s...   \n",
       "4     Shares of JD.com Inc(ADR) (NASDAQ:JD) have set...   \n",
       "...                                                 ...   \n",
       "5343  The virus causing coronavirus disease 2019 (CO...   \n",
       "5344  Tencent, the operator of major Chinese social ...   \n",
       "5345  A roundup of notable music industry deals from...   \n",
       "5346  Looks like Tencent has plans to release some a...   \n",
       "5347  (Bloomberg) -- Unprecedented demand for online...   \n",
       "\n",
       "                                                    url           publishedAt  \\\n",
       "0     https://chinadigitaltimes.net/2017/11/katy-per...  2017-11-08T02:59:56Z   \n",
       "1     https://www.bloomberg.com/news/articles/2017-1...  2017-11-08T15:07:48Z   \n",
       "2     https://japantoday.com/category/tech/update-2-...  2017-11-09T22:24:06Z   \n",
       "3     https://cleantechnica.com/2017/11/09/didis-hug...  2017-11-09T23:50:30Z   \n",
       "4     https://finance.yahoo.com/news/why-buy-jd-com-...  2017-11-09T17:05:21Z   \n",
       "...                                                 ...                   ...   \n",
       "5343  https://science.sciencemag.org/content/368/649...  2020-04-30T17:38:23Z   \n",
       "5344  https://cointelegraph.com/news/chinese-interne...  2020-04-30T10:55:00Z   \n",
       "5345  https://www.billboard.com/articles/business/93...  2020-04-30T13:00:22Z   \n",
       "5346  https://gonintendo.com/stories/360246-tencent-...  2020-04-30T13:30:00Z   \n",
       "5347  https://finance.yahoo.com/news/south-africa-st...  2020-04-30T06:50:05Z   \n",
       "\n",
       "                                                content  \\\n",
       "0     On Monday, CDT Chinese reposted a letter circu...   \n",
       "1     Bank of Amazon. Facebook Financial. Wal-Bank. ...   \n",
       "2     Chinese gaming and social media company Tencen...   \n",
       "3     Cars Published on November 9th, 2017 | by Tim ...   \n",
       "4     Shares of JD.com Inc(ADR) (NASDAQ: JD ) have s...   \n",
       "...                                                 ...   \n",
       "5343  Abstract\\r\\nEstimation of the prevalence and c...   \n",
       "5344  Tencent, the operator of Chinese social media ...   \n",
       "5345  Gaming and esports brand HyperX will collabora...   \n",
       "5346  Looks like Tencent has plans to release some a...   \n",
       "5347  (Bloomberg) --\\r\\nUnprecedented demand for onl...   \n",
       "\n",
       "                       from        date  \n",
       "0     Chinadigitaltimes.net  2017-11-08  \n",
       "1                 Bloomberg  2017-11-08  \n",
       "2            Japantoday.com  2017-11-09  \n",
       "3         Cleantechnica.com  2017-11-09  \n",
       "4                 Yahoo.com  2017-11-09  \n",
       "...                     ...         ...  \n",
       "5343         Sciencemag.org  2020-04-30  \n",
       "5344      Cointelegraph.com  2020-04-30  \n",
       "5345          Billboard.com  2020-04-30  \n",
       "5346         Gonintendo.com  2020-04-30  \n",
       "5347              Yahoo.com  2020-04-30  \n",
       "\n",
       "[5348 rows x 8 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
